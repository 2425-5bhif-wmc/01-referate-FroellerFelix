= Telemetrie
:toc:
:icons: font
ifdef::env-ide[]
:imagesdir: ../images
endif::[]
ifndef::env-ide[]
:imagesdir: images
endif::[]

== Einleitung

Warum Verwendet man Telemetrie?
Um diese Frage zu beantworten, müssen wir uns zuerst mit dem Problem beschäftigen, das Telemetrie löst.

=== Welches Problem gibt es?

* Aufgabenstellung
** Fehlerquellen identifizieren
** Performance optimieren
* Herausforderungen
** Analyse von komplexen Anwendungen (z.B.: k8s).
** Mangelnde Übersicht und fehlende Kennzahlen.

=== Was ist Telemetrie?

* Definition: Automatische Sammlung von Metriken, Logs und Events.
* Aufgabe: Systemzustand analysieren und optimieren.
* Bestandteile: Metriken (Zähler, Timer), Logs, Tracing.

=== Wie Telemetrie dieses Problem löst

* Einblicke in Systemzustände.
* Erleichtert Fehlerdiagnose und Performance-Monitoring.
** Option einer grafischen Darstellung
** Automatisierte Alarme und Benachrichtigungen.

=== Beispiel: Kubernetes-Cluster

* Metriken: CPU- und Speicherauslastung.
* Logs: Fehlermeldungen und Debug-Informationen.
* Tracing
** Nachverfolgung von Requests und wie lange sie wofür brauchen.
** Bottlenecks identifizieren

== Micrometer

=== Was ist Micrometer?

* Java-basierte Bibliothek für Metrik-Sammlung.
** https://quarkus.io/guides/telemetry-micrometer[Wird in der offiziellen Quarkus-Dokumentation empfohlen.]
* Unterstützt verschiedene Metrik-Typen (Zähler, Timer, Histogramm).
* https://prometheus.io/[Prometheus-kompatibel.]
** https://prometheus.io/docs/prometheus/latest/storage/[Sammelt und speichert die Metriken entweder im RAM oder in einer Time Series Database.]

=== Micrometer in der Praxis

* Integration mit Quarkus:
- Einfaches Hinzufügen durch Erweiterungen (`micrometer-registry-prometheus`).
- Erfassung von JVM-Metriken (Heap, Garbage Collection, Threads).
* Visualisierung: Daten an Prometheus senden, mit Grafana anzeigen.

=== Live Demo: Micrometer in Quarkus

image::architecture-prometheus-grafana.png[]

https://exceptionly.com/2022/01/18/monitoring-quarkus-with-prometheus-and-grafana/

=== Schritt 1: Micrometer in Quarkus einbinden

`quarkus-micrometer-prometheus`-Dependency hinzufügen.

=== Schritt 2: Metriken sammeln

https://www.baeldung.com/quarkus-micrometer[Eigene Metriken definieren.]

[source,java]
----
@Path("/palindrome")
@Produces("application/json")
public class PalindromeResource {
    private final MeterRegistry registry;
    private final LinkedList<String> list = new LinkedList<>();

    public PalindromeResource(MeterRegistry registry) {
        this.registry = registry;
        registry.gaugeCollectionSize("palindrome.list.size", Tags.empty(), list);
    }

    @GET
    @Path("counter/check/{input}")
    public boolean checkPalindromeCounter(@PathParam("input") String input) {
        list.add(input);

        registry.counter("palindrome.counter").increment();
        boolean result = internalCheckPalindrome(input);
        return result;
    }

    @GET
    @Path("timer/check/{input}")
    public boolean checkPalindromeAndTimer(@PathParam("input") String input) {
        list.add(input);

        Timer.Sample sample = Timer.start(registry);
        boolean result = internalCheckPalindrome(input);
        sample.stop(registry.timer("palindrome.timer"));
        return result;
    }

    private boolean internalCheckPalindrome(String input) {
        int left = 0;
        int right = input.length() - 1;

        while (left < right) {
            if (input.charAt(left) != input.charAt(right)) {
                return false;
            }
            left++;
            right--;
        }
        return true;
    }

    @DELETE
    @Path("empty-list")
    public void emptyList() {
        list.clear();
    }
}
----

=== Schritt 3: Package erstellen

[source,bash]
----
mvn package
----

=== Schritt 4: Container mit Quarkus, Prometheus und Grafana starten

[source,yaml]
----
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    restart: always
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    restart: always
    networks:
      - monitoring

  quarkus:
    build:
      context: ../../../
      dockerfile: ./src/main/docker/Dockerfile.jvm
    container_name: quarkus
    ports:
      - "8080:8080" # Optional, for host access
    restart: always
    networks:
      - monitoring

networks:
  monitoring:
    driver: bridge
----

=== Schritt 5: Prometheus

http://localhost:9090

=== Schritt 6: Grafana

http://localhost:3000

=== Alternativen zu Micrometer

* Dropwizard Metrics:
- Älter, weniger flexibel.
* Spring Boot Actuator (eingebaut, aber weniger universell).
* OpenTelemetry (vollständige Lösung für Telemetrie inkl.
Tracing).

=== Beispiel

Das Beispiel ist in diesem Repository unter `quarkus-micrometer-demo` zu finden.

== Tracing

=== Welches Problem gibt es?

* Identifizierung von Performance-Problemen
* Bottleneck identifizieren
* Warum dauert ein Request so lange?

=== Was ist Tracing?

* Nachverfolgung von Requests auf der Seite des Servers
* Analyse von vielen Requests
* Zeit zwischen einzelnen Schritten messen

=== Was ist ein Trace?

image::spans-traces.png[spans-traces]

Ein Trace besteht aus Aufgaben über eine Zeitspanne, sogenannte Spans.

Theoretisches Beispiel, welches so in LeoVote vorkommen könnte und sich an der obigen Abbildung orientiert:

* *Span A* - Wahleinladungen senden
** *Span B* - E-Mails vorbereiten
*** *Span C* - DB Abfrage für E-Mails der Wähler
*** *Span D* - Link für die E-Mail generieren
** *Span E* - Emails versenden

== LiveDemo: LeoVote - Tracing mit Jaeger

image::jaeger-logo.png[jaeger-logo,width=200]

=== Tracing in Quarkus

==== OpenTelemetry

OpenTelemetry ist ein Open-Source-Framework zur Sammlung und Verarbeitung von:

* Metriken
* Logs
* Traces

In diesem Beispiel verwenden wir OpenTelemetry Tracing in Quarkus.
Jaeger Tracing wird später die Daten von OpenTelemetry visualisieren.

=== OpenTelemetry Tracing in Quarkus

==== Dependencies

Um OpenTelemetry Tracing in Quarkus zu verwenden, müssen wir die folgenden Abhängigkeiten hinzufügen:

[source,xml]
----
<dependency>
    <groupId>io.quarkus</groupId>
    <artifactId>quarkus-opentelemetry</artifactId>
</dependency>
<dependency>
    <groupId>io.opentelemetry.instrumentation</groupId>
    <artifactId>opentelemetry-jdbc</artifactId>
</dependency>
----

==== Application.properties

In der `application.properties`-Datei müssen wir die folgenden Einstellungen vornehmen:

[source,yaml]
----
# Enable OpenTelemetry tracing

quarkus.otel.exporter.otlp.endpoint=http://localhost:4317 <1>

quarkus.otel.traces.sampler=always_on <2>

quarkus.otel.service.name=quarkus-backend <3>

# For JDBC telemetry
quarkus.datasource.jdbc.telemetry=true <4>
----

<1> Der Endpunkt, an den die Tracing-Daten gesendet werden.
<2> Der Traces-Sampler, der bestimmt, ob ein Trace erfasst und exportiert wird.
Die Einstellung `always_on` bedeutet, dass alle Traces erfasst werden.
<3> Der Name des Services, der in den Traces angezeigt wird.
Dieser Name wird in Jaeger als Source verwendet.
<4> Aktiviert die Erfassung von JDBC-Telemetrie.
Damit können wir die Dauer von Datenbankabfragen messen.

==== Jaeger Tracing

[source,yaml]
----
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: simplest
----

=== Live Demo

LeoVote

=== Custom Span

[source,java]
----
public Uni<Response> sendInvite(@PathParam("electionId") Long electionId) {
Span span = tracer.spanBuilder("sendEmails").startSpan();

        Optional<Election> election = Election.findByIdOptional(electionId);

        if (election.isEmpty()) {
            return Uni.createFrom().item(Response.status(Response.Status.NOT_FOUND).build());
        }

        try (Scope scope = span.makeCurrent()) {

            // Perform email sending logic in a background task
            emailService.sendInvitations(election.get()).subscribe().with(
                    success -> System.out.println("Emails sent successfully"),
                    failure -> System.out.println("Emails could not be sent\n" + failure.toString())
            );
        } finally {
            span.end();
        }

        return Uni.createFrom().item(Response.ok().entity("{\"message\": \"Emails are being sent asynchronously.\"}").build());
    }
----

=== Jaeger in Docker

[source,bash]
----
docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.6.0
----

=== Deployment auf Kubernetes

[source,bash]
----
minikube start --cpus 15 --memory=8g --driver=docker
----

Add ingress.

[source,bash]
----
minikube addons enable ingress
----

[source,bash]
----
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.16.2/cert-manager.yaml
----

[source,bash]
----
kubectl create namespace observability
----

[source,bash]
----
export WORKING_DIR=/tmp/jaeger
export NAMESPACE=observability  # Change if needed
----

[source,bash]
----
rm -rf ${WORKING_DIR}
mkdir -p ${WORKING_DIR}
----

[source,bash]
----
./cert_generation.sh
----

[source,bash]
----
kubectl create -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.62.0/jaeger-operator.yaml -n observability
----

[source,bash]
----
kubectl delete secret jaeger-operator-service-cert -n observability
kubectl create secret tls jaeger-operator-service-cert \
  --cert=${WORKING_DIR}/user.jaeger.crt \
  --key=${WORKING_DIR}/user.jaeger.key \
  -n observability
----

Im Leovote projekt in den k8s Ordner wechseln und folgendes ausführen:

[source,bash]
----
kubectl apply -f .
----

Es kommt ein Error deshalb einfach das ausführen:

[source,bash]
----
kubectl apply -f ./jaeger.yaml
----

Um darauf zuzugreifen:

[source,bash]
----
minikube ip
----

=== Deployment auf VM

Das LeoVote Projekt wurde auf eine virtuelle Machine deployed.
Es wurde folgendermaßen realisiert.

. Backend builden
* mvn build --clean
. Frontend builden
* ng build
. Auf Server kopieren mit "scp"
* Jar-Datei und frontend Verzeichnis auf den Server kopieren

==== Automatisches Starten

Damit auch bei einem Server Neustart das Front- und Backend automatisch im Hintergrund startet sind folgende Schritte notwendig:

Shellscripts in `/opt/scripts` anlegen:

backend.sh

[source,bash]
----
#!/bin/bash
cd /home/lvadm && java -jar ./backend-1.0-SNAPSHOT-runner.jar
----

jaeger.sh

[source,bash]
----
#!/bin/bash

docker run -d --name jaeger \
  -e COLLECTOR_ZIPKIN_HTTP_PORT=9411 \
  -p 5775:5775/udp \
  -p 6831:6831/udp \
  -p 6832:6832/udp \
  -p 5778:5778 \
  -p 16686:16686 \
  -p 14268:14268 \
  -p 9411:9411 \
  jaegertracing/all-in-one:1.62.0

----

In den Auto-Start hinzufügen:

[source,bash]
----
crontab -e
----

Folgendes hinzufügen:
[source, text]
----
@reboot screen -dm -S backend /opt/scripts/backend.sh
@reboot screen -dm -S jaeger /opt/scripts/jaeger.sh
----

nginx.conf in `/etc/nginx/sites-enabled/default` anpassen:

[source, text]
----
server {
	index index.html index.htm index.nginx-debian.html;

	server_name leovote.htl-leonding.ac.at;

	location /api/services {
		proxy_pass http://localhost:16686/api/services;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme;
	}

	location /api/traces {
		proxy_pass http://localhost:16686/api/traces;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme;
	}

    location /api/dependencies {
        proxy_pass http://localhost:16686/api/dependencies;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /api/metrics {
        proxy_pass http://localhost:16686/api/metrics/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    location /api/monitor {
        proxy_pass http://localhost:16686/api/monitor;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

	location /api/ {
		proxy_pass http://localhost:8080/; # Quarkus application
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme;
	}


	location / {
		root /home/lvadm/frontend;
		try_files $uri $uri/ /index.html;
	}

	location /tracing/ {
		proxy_pass http://localhost:16686/;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme;

		# Fix paths for static files
		sub_filter '/static/' '/tracing/static/';
		sub_filter_once off;

		# Required for sub_filter to work
		proxy_http_version 1.1;
		proxy_set_header Accept-Encoding ""; # Ensure sub_filter processes responses
	}

	location /tracing/static/ {
		proxy_pass http://localhost:16686/static/;
		proxy_set_header Host $host;
		proxy_set_header X-Real-IP $remote_addr;
		proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		proxy_set_header X-Forwarded-Proto $scheme;
	}

    listen [::]:443 ssl ipv6only=on; # managed by Certbot
    listen 443 ssl; # managed by Certbot
    ssl_certificate /etc/letsencrypt/live/leovote.htl-leonding.ac.at/fullchain.pem; # managed by Certbot
    ssl_certificate_key /etc/letsencrypt/live/leovote.htl-leonding.ac.at/privkey.pem; # managed by Certbot
    include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot

}

server {
    if ($host = leovote.htl-leonding.ac.at) {
        return 301 https://$host$request_uri;
    } # managed by Certbot


	listen 80 default_server;
	listen [::]:80 default_server;

	server_name leovote.htl-leonding.ac.at;
    return 404; # managed by Certbot
}
----

nginx neu starten:

[source,bash]
----
sudo systemctl restart nginx
----

Alternativ kann auch der Server neu gestartet werden. Das Deployment ist auf https://leovote.htl-leonding.ac.at abrufbar. +
Das Jaeger-UI ist hier zu finden: https://leovote.htl-leonding.ac.at/tracing

== Slides

https://2425-5bhif-wmc.github.io/01-referate-FroellerFelix/slides/telemetry.html[Slides]

== Quellen

* https://medium.com/@stackify1/demystifying-observability-telemetry-logs-distributed-tracing-and-monitoring-vs-logging-8f0b972259f7
* https://quarkus.io/guides/telemetry-micrometer
* https://prometheus.io/
* https://prometheus.io/docs/prometheus/latest/storage/
* https://www.baeldung.com/quarkus-micrometer
* https://github.com/jaegertracing/jaeger
